{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Task GANs Implements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as tordata\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd import grad\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from network.network_layer import *\n",
    "from utils.data_load import *\n",
    "from utils.batch_sampler import *\n",
    "from utils.functions import *\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "hidden_dim = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = load_OU_ISIR('./data/OU_ISIR/npy/', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = BatchSampler(train_dataset, batch_size)\n",
    "test_sampler = BatchSampler(test_dataset, batch_size)\n",
    "\n",
    "train_loader = tordata.DataLoader(dataset=train_dataset, batch_sampler=train_sampler, collate_fn=collate_fnn)\n",
    "test_loader = tordata.DataLoader(dataset=test_dataset, batch_sampler=test_sampler, collate_fn=collate_fnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = Encoder().to(device)\n",
    "V = ViewTransformLayer().to(device)\n",
    "G = Generator().to(device)\n",
    "D = Discriminator().to(device)\n",
    "\n",
    "E.weight_init()\n",
    "V.weight_init()\n",
    "G.weight_init()\n",
    "D.weight_init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss & optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_G = torch.optim.RMSprop([{'params': E.parameters()}, {'params': V.parameters()},\n",
    "                              {'params': G.parameters()}], lr=5e-5, weight_decay=1.5e-4)\n",
    "optim_D = torch.optim.RMSprop(D.parameters(), lr=5e-5, weight_decay=1.5e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. E,V,G,D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_losses = []\n",
    "G_losses = []\n",
    "\n",
    "total_iter = 100000\n",
    "cur_iter = 0\n",
    "\n",
    "it = iter(train_loader)\n",
    "while(cur_iter < total_iter):\n",
    "    for i in range(5):\n",
    "        \n",
    "        peis, channel, view, label = it.next()\n",
    "        \n",
    "        D.zero_grad()\n",
    "    \n",
    "        index = [channel[1][i].index(1) for i in range(len(channel[1]))] \n",
    "\n",
    "        input_2 =  Variable(torch.FloatTensor([peis[1][i][j] for i, j in enumerate(index)])).to(device)\n",
    "        input_1 = Variable(torch.FloatTensor(peis[0])).to(device)  \n",
    "        input_ch = Variable(torch.FloatTensor(channel)).to(device)\n",
    "        \n",
    "        enc_view = encode_view_transform(view[0], view[1]).to(device)\n",
    "\n",
    "        latent_trans_view = V(E(input_1), enc_view)\n",
    "        latent_noise = Variable(torch.FloatTensor(np.random.rand(batch_size, hidden_dim)*1e-4)).to(device)\n",
    "        latent_trans_view += latent_noise\n",
    "\n",
    "        latent = torch.cat((latent_trans_view, input_ch[0]), 1)\n",
    "\n",
    "        output_2 = D(input_2)\n",
    "        input_fake = G(latent)\n",
    "        output_1 = D(input_fake)\n",
    "\n",
    "        enc_view_2 = encode_view_onehot(view[1]).to(device)\n",
    "        enc_label_2 = encode_label_onehot(label[1], list(train_dataset.set_label)).to(device)\n",
    "        enc_channel_2 = Variable(torch.FloatTensor(channel[1])).to(device)\n",
    "\n",
    "        flag = torch.cat((enc_view_2, enc_label_2, enc_channel_2), 1)\n",
    "\n",
    "        loss_D_1 = torch.mean(torch.sum(torch.abs((output_1 - output_2)*flag), 1))\n",
    "\n",
    "        alpha = torch.rand(batch_size, 1, 1)\n",
    "        alpha = alpha.expand(input_2.size())\n",
    "        alpha = Variable(alpha.float()).to(device)\n",
    "\n",
    "        interpolates = alpha * input_2 + (1-alpha)*input_fake    \n",
    "        disc_interpolates = torch.mean(torch.sum(D(interpolates)*flag, 1))\n",
    "\n",
    "        gradients = grad(outputs=disc_interpolates, inputs=interpolates, grad_outputs=torch.ones(disc_interpolates.size()).float().to(device),\n",
    "                        create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "        gradients = gradients.view(-1, 64*64)\n",
    "        gradients_penalty = ((gradients.norm(2, dim=1) - 1)**2).mean() * 10\n",
    "\n",
    "        loss_D = loss_D_1 + gradients_penalty\n",
    "        \n",
    "        loss_D.backward()\n",
    "        optim_D.step()\n",
    "        \n",
    "    for i in range(1):\n",
    "        \n",
    "        peis, channel, view, label = it.next()\n",
    "        \n",
    "        E.zero_grad()\n",
    "        V.zero_grad()\n",
    "        G.zero_grad()\n",
    "\n",
    "        latent_trans_view = V(E(input_1), enc_view)\n",
    "        latent_noise = Variable(torch.FloatTensor(np.random.rand(batch_size, hidden_dim) * 1e-4)).to(device)\n",
    "        latent_trans_view += latent_noise\n",
    "\n",
    "        latent = torch.cat((latent_trans_view, input_ch[0]), 1)\n",
    "\n",
    "        input_fake = G(latent)\n",
    "        output_1 = D(input_fake)\n",
    "        \n",
    "        flag = torch.cat((enc_view_2, enc_label_2, enc_channel_2), 1)\n",
    "\n",
    "        loss_G_1 = torch.mean(torch.abs(input_2 - input_fake))\n",
    "        loss_G_2 = torch.mean(torch.sum(-output_1*flag, 1))\n",
    "\n",
    "        loss_G = loss_G_1 + 1e-5*loss_G_2\n",
    "\n",
    "        loss_G.backward(retain_graph=True)\n",
    "        optim_G.step()\n",
    "\n",
    "        G_losses.append(loss_G.item())\n",
    "        D_losses.append(loss_D.item())\n",
    "        \n",
    "    if (cur_iter+1) % 100 == 0:\n",
    "        print('iteration : [{}/{}]'.format(cur_iter+1, total_iter))\n",
    "        drawLoss({'G':G_losses, 'D':D_losses})\n",
    "        \n",
    "    if (cur_iter+1)%200 == 0:\n",
    "        plt.imshow(input_fake[batch_size-1].detach().cpu().numpy(), cmap='gray')\n",
    "        plt.savefig(\"./images/Fake_Images_{}.png\".format(cur_iter+1))\n",
    "        \n",
    "    cur_iter += 1\n",
    "    \n",
    "drawLoss({'G':G_losses, 'D':D_losses})\n",
    "\n",
    "torch.save(E.state_dict(), os.path.join('./checkpoint/', 'OU_ISIR_E.ptm'))\n",
    "torch.save(V.state_dict(), os.path.join('./checkpoint/', 'OU_ISIR_V.ptm'))\n",
    "torch.save(G.state_dict(), os.path.join('./checkpoint/', 'OU_ISIR_G.ptm'))\n",
    "torch.save(D.state_dict(), os.path.join('./checkpoint/', 'OU_ISIR_D.ptm'))\n",
    "\n",
    "torch.save(optim_G.state_dict(), os.path.join('./checkpoint/', 'OU_ISIR_Optim_G.ptm'))\n",
    "torch.save(optim_D.state_dict(), os.path.join('./checkpoint/', 'OU_ISIR_Optim_D.ptm'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. View-angle Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAC = ViewAngleClassifier2().to(device)\n",
    "\n",
    "VAC.weight_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_VAC = torch.optim.Adam([{'params':VAC.parameters()}], lr=1e-4, weight_decay=1.5e-4)\n",
    "\n",
    "criterion_VAC = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "E.load_state_dict(torch.load('./checkpoint/OU_ISIR_E.ptm'))\n",
    "V.load_state_dict(torch.load('./checkpoint/OU_ISIR_V.ptm'))\n",
    "G.load_state_dict(torch.load('./checkpoint/OU_ISIR_G.ptm'))\n",
    "D.load_state_dict(torch.load('./checkpoint/OU_ISIR_D.ptm'))\n",
    "\n",
    "optim_G.load_state_dict(torch.load('./checkpoint/OU_ISIR_Optim_G.ptm'))\n",
    "optim_D.load_state_dict(torch.load('./checkpoint/OU_ISIR_Optim_D.ptm'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAC.load_state_dict(torch.load('./checkpoint/OU_ISIR_VAC.ptm'))\n",
    "\n",
    "optim_VAC.load_state_dict(torch.load('./checkpoint/OU_ISIR_Optim_VAC.ptm'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAC_losses = []\n",
    "\n",
    "it = iter(train_loader)\n",
    "for i in range(10000):\n",
    "    VAC.zero_grad()\n",
    "    \n",
    "    peis, channel, view, label = it.next()\n",
    "    \n",
    "    input_1 = Variable(torch.FloatTensor(peis[0])).to(device)\n",
    "    view_1 = Variable(torch.LongTensor(view[0])).to(device)    \n",
    "    \n",
    "    latent = E(input_1)\n",
    "        \n",
    "    loss = criterion_VAC(VAC(latent), view_1)\n",
    "\n",
    "    loss.backward()\n",
    "    \n",
    "    optim_VAC.step()\n",
    "    \n",
    "    VAC_losses.append(loss.item())\n",
    "    \n",
    "    if (i+1) % 100 == 0:\n",
    "        print('iteration : [{}/{}]'.format(i+1, 10000))\n",
    "        drawLoss({'VAC':VAC_losses})\n",
    "\n",
    "\n",
    "torch.save(VAC.state_dict(), os.path.join('./checkpoint/', 'OU_ISIR_VAC.ptm'))\n",
    "torch.save(optim_VAC.state_dict(), os.path.join('./checkpoint/', 'OU_ISIR_Optim_VAC.ptm'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E.load_state_dict(torch.load('./checkpoint/OU_ISIR_E.ptm'))\n",
    "V.load_state_dict(torch.load('./checkpoint/OU_ISIR_V.ptm'))\n",
    "VAC.load_state_dict(torch.load('./checkpoint/OU_ISIR_VAC.ptm'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_loader = tordata.DataLoader(dataset=test_dataset, batch_size=batch_size, collate_fn=collate_fnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuda_dist(x, y):\n",
    "    \n",
    "    dist = torch.sum(x ** 2, 1).unsqueeze(1) + torch.sum(y ** 2, 1).unsqueeze(\n",
    "        1).transpose(0, 1) - 2 * torch.matmul(x, y.transpose(0, 1))\n",
    "    dist = torch.sqrt(F.relu(dist))\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[81.26160714 92.39910714 96.19375    97.88928571 98.80535714]\n"
     ]
    }
   ],
   "source": [
    "pool = mp.Pool(processes=6)\n",
    "\n",
    "it = iter(test_loader)\n",
    "num_rank = 5\n",
    "\n",
    "total_acc = 0\n",
    "total_cnt = 0\n",
    "\n",
    "for i in range(1000):    \n",
    "    for v in range(1, 15):\n",
    "    \n",
    "        peis, channel, view, label = it.next()\n",
    "\n",
    "        input_1 = Variable(torch.FloatTensor(peis[0])).to(device) \n",
    "        input_2 = Variable(torch.FloatTensor(peis[1])).to(device)\n",
    "        \n",
    "        latent_1 = E(input_1)\n",
    "        latent_2 = E(input_2)\n",
    "        \n",
    "        view_1 = torch.max(VAC(latent_1), 1)[1].data.cpu().numpy() + 1\n",
    "        view_2 = torch.max(VAC(latent_2), 1)[1].data.cpu().numpy() + 1\n",
    "\n",
    "        tar_view = [v for _ in range(len(view[0]))]\n",
    "\n",
    "        view_trans_1 = encode_view_transform(view_1, tar_view).to(device)\n",
    "        view_trans_2 = encode_view_transform(view_2, tar_view).to(device)\n",
    "\n",
    "        feature_1 = V(latent_1, view_trans_1).detach().cpu().numpy()\n",
    "        feature_2 = V(latent_2, view_trans_2).detach().cpu().numpy()\n",
    "        \n",
    "        feature_1 = feature_1 / np.tile(np.reshape(np.linalg.norm(feature_1, 2, 1), [-1, 1]), [1, feature_1.shape[1]])\n",
    "        feature_2 = feature_2 / np.tile(np.reshape(np.linalg.norm(feature_2, 2, 1), [-1, 1]), [1, feature_2.shape[1]])\n",
    "        \n",
    "        n, _ = feature_1.shape\n",
    "        \n",
    "        dist = distance.cdist(feature_1, feature_2)\n",
    "        idx = np.argsort(dist, 1)\n",
    "    \n",
    "        acc = np.round(np.sum(np.cumsum(np.reshape(np.array(label[0]), [-1, 1]) == np.array(label[1])[idx[:, 0:num_rank]], 1) > 0, 0)*100 / dist.shape[0], 2)\n",
    "        total_acc += acc\n",
    "        total_cnt += 1\n",
    "        \n",
    "total_acc = total_acc / total_cnt\n",
    "print(total_acc)\n",
    "\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112000, 512)\n"
     ]
    }
   ],
   "source": [
    "print(test_prob.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
